#import libraries
library(readr)
library(ggplot2)
library(tidyverse)
library(scales)
library(tidytext)
library(rtweet)
library(dplyr)
library(stringr)
library(tidyr)
library(scales)
library(textdata)
library(stringr) 
library(reshape2)
library(igraph)
library(ggraph)
library(RColorBrewer)
library(wordcloud)

#import stop words list
data(stop_words)

#import the dataset
fake <- read_csv("D:/Formazione/Hult/MSBA/2- Text Analytics and Natural Language Processing/Assignment/Fake.csv")
real <- read_csv("D:/Formazione/Hult/MSBA/2- Text Analytics and Natural Language Processing/Assignment/True.csv")

#checking the subject
fake %>% 
  count(subject) %>% 
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(x = subject, y = prop)) +
  geom_col(fill = "#FF7F24") +
  geom_text(aes(label = percent(prop)), vjust = -1) +
  coord_cartesian(clip = "off") +
  scale_y_continuous(labels = percent_format()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust = 1),
        axis.title = element_blank(),
        plot.margin = margin(t = 20, r = 10, b = 10, l = 10))

real%>% 
  count(subject) %>% 
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(x = subject, y = prop)) +
  geom_col(fill = "#00CD00") +
  geom_text(aes(label = percent(prop)), vjust = -1) +
  coord_cartesian(clip = "off") +
  scale_y_continuous(labels = percent_format()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust = 1),
        axis.title = element_blank(),
        plot.margin = margin(t = 20, r = 10, b = 10, l = 10))

#create the tidy dataframes
tidy_fake <- fake %>%
  unnest_tokens(word,text) %>%
  anti_join(stop_words)

tidy_real <- real %>%
  unnest_tokens(word,text) %>%
  anti_join(stop_words)

#plot token  frequencies
freq_hist_fake <- tidy_fake %>%
  count(word, sort=TRUE) %>%
  filter(n>7000) %>% # we need this to eliminate all the low count words
  mutate(word = reorder(word,n )) %>%
  ggplot(aes(word, n))+
  geom_col(fill = "#FF7F24")+
  xlab(NULL)+
  coord_flip()
print(freq_hist_fake)

freq_hist_real <- tidy_real%>%
  count(word, sort=TRUE) %>%
  filter(n>8000) %>% # we need this to eliminate all the low count words
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n))+
  geom_col(fill = "#00CD00")+
  xlab(NULL)+
  coord_flip()
print(freq_hist_real)

#combining together in the same df
frequency <- bind_rows(mutate(tidy_fake, who="Fake"),
                       mutate(tidy_real, who="Real"),

)%>%#closing bind_rows
  mutate(word=str_extract(word, "[a-z']+")) %>%
  count(who, word) %>%
  group_by(who) %>%
  mutate(proportion = n/sum(n))%>%
  select(-n) %>%
  spread(who, proportion) %>%
  gather(who, proportion, `Fake`)

#plot the correlograms:
ggplot(frequency, aes(x=proportion, y=`Real`, 
                      color = (`Real`- proportion)))+
  geom_abline(color="grey40", lty=2)+
  geom_jitter(alpha=.2, size=2.5, width=0.3, height=0.3)+
  geom_text(aes(label=word), check_overlap = TRUE, vjust=0.1, colour= "black", alpha= 0.6) +
  scale_x_log10(labels = percent_format())+
  scale_y_log10(labels= percent_format())+
  scale_color_gradient(limits = c(0,1), low = "#00CD00", high = "grey40", na.value = "#FF7F24")+
  facet_wrap(~who, ncol=2)+
  theme(legend.position = "none")+
  labs(y= "Real", x=NULL)

cor.test(data=frequency[frequency$who == "Fake",],
         ~proportion + `Real`)

#import sentiment analysis dataframes
afinn <- get_sentiments("afinn")
nrc <- get_sentiments("nrc")
bing <- get_sentiments("bing")

#collecting all the dataframes into one
sentiments <- bind_rows(mutate(afinn, lexicon="afinn"),
                        mutate(nrc, lexicon= "nrc"),
                        mutate(bing, lexicon="bing")
)

#list of emotions in nrc
unique(sentiments$sentiment)

#check and comparison for every emotion
for (i in unique(sentiments$sentiment)){
  print(i)
  nrc_actual <- get_sentiments("nrc") %>%
    filter(sentiment == i)

  fake_i <- tidy_fake %>%
          inner_join(nrc_actual) %>%
          count(word, sort=T)
  fake_score <- sum(fake_i$n)/nrow(fake)
  print(paste0("fake score: ", fake_score))
  real_i <- tidy_real %>%
          inner_join(nrc_actual) %>%
          count(word, sort=T)
  real_score <- sum(real_i$n)/nrow(real)
  print(paste0("real score: ",real_score))
  
  to_plot <- c(fake_score, real_score)
  print(ggplot(data.frame(to_plot),aes(c("Fake", "Real"),to_plot))+
    geom_bar(stat="identity")+
    scale_fill_manual(values=c("#FF7F24", "#00CD00"))+
      ggtitle(paste0(str_to_title(i)," Score"))+
      theme_minimal() +
      theme(axis.text.x = element_text(angle=45, hjust=1, vjust = 1),
            axis.title = element_blank(),
            plot.margin = margin(t = 20, r = 10, b = 10, l = 10))+ 
      geom_col(fill = c("#FF7F24", "#00CD00"))
  )
}

#cluster comparison by emotion
tidy_fake %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word, sentiment, sort=TRUE) %>%
  acast(word ~sentiment, value.var="n", fill=0) %>%
  comparison.cloud(color = rep.int("#FF7F24",10),
                   max.words=100, scale = c(1,0.8))

par(new=TRUE)

tidy_real %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word, sentiment, sort=TRUE) %>%
  acast(word ~sentiment, value.var="n", fill=0) %>%
  comparison.cloud(color = rep.int("#00CD00",10),
                   max.words=100, scale = c(1,0.8))

#cluster comparison by positive/negative
tidy_fake %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort=TRUE) %>%
  acast(word ~sentiment, value.var="n", fill=0) %>%
  comparison.cloud(color = rep.int("#FF7F24",10),
                   max.words=100, scale = c(1,0.8))

par(new=TRUE)

tidy_real %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort=TRUE) %>%
  acast(word ~sentiment, value.var="n", fill=0) %>%
  comparison.cloud(color = rep.int("#00CD00",10),
                   max.words=100, scale = c(1,0.8))


#look at tf-idf
fake_tf_idf <- tidy_fake %>%
  group_by(subject) %>%
  count(word, sort=TRUE) %>%
  ungroup()%>%
  bind_tf_idf(word, subject, n)


fake_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels=rev(unique(word)))) %>%
  group_by(subject) %>%
  filter(n<60) %>%
  top_n(10) %>%
  ungroup %>%
  ggplot(aes(word, tf_idf, fill=subject))+
  geom_col(show.legend=FALSE)+
  labs(x=NULL, y="tf-idf")+
  facet_wrap(~subject, ncol=2, scales="free")+
  coord_flip()

real_tf_idf <- tidy_real %>%
  group_by(subject) %>%
  count(word, sort=TRUE) %>%
  ungroup()%>%
  bind_tf_idf(word, subject, n)


real_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels=rev(unique(word)))) %>%
  group_by(subject) %>%
  filter(n<30) %>%
  top_n(5) %>%
  ungroup %>%
  ggplot(aes(word, tf_idf, fill=subject))+
  geom_col(show.legend=FALSE)+
  labs(x=NULL, y="tf-idf")+
  facet_wrap(~subject, ncol=2, scales="free")+
  coord_flip()

nrow(filter(fake, fake$subject == "Middle-east"))
nrow(filter(fake, fake$subject == "left-news"))
nrow(filter(fake, fake$subject == "Government News"))
nrow(filter(fake, fake$subject == "News"))
nrow(filter(fake, fake$subject == "politics"))
nrow(filter(fake, fake$subject == "US_News"))


#ngram analysis
fake_bigram <- fake %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  filter(!is.na(bigram)) %>% 
  separate(bigram, c("word1", "word2"), sep=" ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

fake_bigram_counts <- fake_bigram %>%
  count(word1, word2, sort = TRUE)

fake_bigram_graph <- fake_bigram_counts %>%
  filter(n>300) %>%
  graph_from_data_frame()
bigram_graph

ggraph(fake_bigram_graph, layout = "fr") +
  geom_edge_link(aes(color="#FF7F24",alpha = .4))+
  geom_node_point(aes(color="#FF7F24",alpha = .4))+
  geom_node_text(aes(label = name), vjust =1, hjust=1,check_overlap = TRUE)+
  theme(legend.position = 'none')



real_bigram <- real %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  filter(!is.na(bigram)) %>%
  separate(bigram, c("word1", "word2"), sep=" ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

real_bigram_counts <- real_bigram %>%
  count(word1, word2, sort = TRUE)

real_bigram_graph <- real_bigram_counts %>%
  filter(n>400) %>%
  graph_from_data_frame()


ggraph(real_bigram_graph, layout = "fr") +
  geom_edge_link(aes(color="#00CD00",alpha = .4))+
  geom_node_point(aes(color="#00CD00",alpha = .4))+
  geom_node_text(aes(label = name), vjust =1, hjust=1,check_overlap = TRUE)+
  theme(legend.position = 'none')
